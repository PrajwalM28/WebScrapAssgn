{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e470b3e6-f069-4ebe-99f2-66a3485e1ab1",
   "metadata": {},
   "source": [
    "## Q1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797cee7a-9b5f-4d51-955e-6eb9a9cd2b0c",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Web scraping is the process of automatically extracting data from websites. It involves sending HTTP requests to web pages, parsing the HTML or other structured data on those pages, and then extracting specific information. \n",
    "\n",
    "Uses : \n",
    " - Data Collections\n",
    " - Business Intelligence\n",
    " - Research and Analysis\n",
    " - Lead Generation\n",
    " - Price Comparison\n",
    " \n",
    "Specific areas : \n",
    " - E-commerce and Price Comparison\n",
    " - Real Estate and Property Listings\n",
    " - Social Media and Sentiment Analysis\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92fbc69-66fd-4fb1-876d-12da9ade036d",
   "metadata": {},
   "source": [
    "## Q2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c3f8d9-36f5-40a5-bae2-b4339e1310af",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    " - Manual Copy-Paste\n",
    " - HTML Parsing\n",
    " - XPath and CSS Selectors\n",
    " - Regex\n",
    " - Scrapping Frameworks and tools\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c3e701-b43c-45fb-8174-c0d563edd836",
   "metadata": {},
   "source": [
    "## Q3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc5fce5-cb19-4f05-b630-47d84305c0ff",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Beautiful Soup is a Python library that is commonly used for web scraping and parsing HTML or XML documents. It provides a convenient way to navigate and manipulate the elements of a web page's Document Object Model (DOM). \n",
    "\n",
    " - Parsing HTML and XML\n",
    " - Simplifies Web Scrapping\n",
    " - Element Navigation\n",
    " - Data Extraction\n",
    " - Open source and Widely Adopted\n",
    " \n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d4b973-6e82-47c6-a6eb-03f787c6d4e4",
   "metadata": {},
   "source": [
    "## Q4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea32583-d35a-44b6-b904-129abf12684a",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    " - Data Representations\n",
    " - Data Storage and Retrieval\n",
    " - Automation\n",
    " - Integration\n",
    " - Visualization and Analytics\n",
    " - API Endpoints\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba8d92d-1855-4cad-9497-9ae07c5af1ff",
   "metadata": {},
   "source": [
    "## Q5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032582d3-5750-4cc1-8ccb-07d4fc891257",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    " - EC2 (Elastic Compute Cloud):\n",
    "\n",
    "Use: EC2 instances can be used for running web scraping scripts or applications. These virtual machines provide compute capacity in the cloud, allowing you to run your scraping code on scalable and customizable instances.\n",
    "\n",
    " - S3 (Simple Storage Service):\n",
    "\n",
    "Use: S3 is an object storage service that can be used to store scraped data. You can save the data files, such as HTML, JSON, or CSV, in S3 buckets for easy access, sharing, and further processing.\n",
    "\n",
    " - DynamoDB:\n",
    "\n",
    "Use: DynamoDB is a NoSQL database service. You can use it to store structured data from your web scraping, such as metadata, URLs, or other data that requires fast and scalable database storage.\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
